import "dotenv/config";
import OpenAI from "openai";

/**
 * API da Betgram IA â€” fallback automÃ¡tico entre GPT-5-nano e GPT-5-mini.
 * Garante resposta mesmo que o modelo nano retorne vazio.
 */
export async function POST(req) {
  try {
    const { prompt } = await req.json();

    if (!prompt || typeof prompt !== "string" || prompt.trim().length < 3) {
      return new Response(JSON.stringify({ error: "Prompt invÃ¡lido." }), { status: 400 });
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.error("âŒ OPENAI_API_KEY ausente no ambiente Vercel.");
      return new Response(
        JSON.stringify({ error: "Chave da OpenAI ausente. Configure nas variÃ¡veis da Vercel." }),
        { status: 500 }
      );
    }

    const openai = new OpenAI({ apiKey });

    // ğŸ”¹ FunÃ§Ã£o auxiliar para tentar um modelo e retornar resposta
    const gerarComModelo = async (modelo) => {
      console.log(`ğŸ§  Gerando anÃ¡lise com ${modelo}...`);
      const completion = await openai.chat.completions.create({
        model: modelo,
        messages: [
          {
            role: "system",
            content:
              "VocÃª Ã© a Betgram IA â€” analista esportivo profissional. Gere previsÃµes e anÃ¡lises claras e objetivas sobre apostas esportivas.",
          },
          { role: "user", content: prompt },
        ],
        max_completion_tokens: 2500,
      });

      return completion.choices?.[0]?.message?.content?.trim() || "";
    };

    // ğŸ§  1Âª tentativa com GPT-5-nano
    let resposta = await gerarComModelo("gpt-5-nano-2025-08-07");

    // ğŸ” Se o modelo nano nÃ£o gerar nada, tenta o mini
    if (!resposta || resposta.length < 3) {
      console.warn("âš ï¸ Nano retornou vazio â€” tentando gpt-5-mini-2025-08-07...");
      resposta = await gerarComModelo("gpt-5-mini-2025-08-07");
    }

    // ğŸ”š Se mesmo assim nÃ£o houver resposta, informa
    if (!resposta) resposta = "(sem resposta gerada pelos modelos)";

    console.log("âœ… Resposta final:", resposta.slice(0, 120) + "...");

    return new Response(JSON.stringify({ resposta }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (err) {
    console.error("ğŸš¨ Erro /api/analise:", err?.response?.data || err);
    const msg =
      err?.response?.data?.error?.message ||
      err?.message ||
      "Falha ao gerar anÃ¡lise.";
    return new Response(JSON.stringify({ error: msg }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
