import "dotenv/config";
import OpenAI from "openai";

/**
 * API da Betgram IA â€” usando GPT-5-mini-2025-08-07 (mais completo e ainda econÃ´mico)
 */
export async function POST(req) {
  try {
    const { prompt } = await req.json();

    if (!prompt || typeof prompt !== "string" || prompt.trim().length < 3) {
      return new Response(JSON.stringify({ error: "Prompt invÃ¡lido." }), { status: 400 });
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.error("âŒ OPENAI_API_KEY ausente no ambiente Vercel.");
      return new Response(
        JSON.stringify({ error: "Chave da OpenAI ausente. Configure nas variÃ¡veis da Vercel." }),
        { status: 500 }
      );
    }

    const openai = new OpenAI({ apiKey });

    console.log("ðŸ”„ Enviando prompt ao GPT-5-mini-2025-08-07â€¦");

    const completion = await openai.chat.completions.create({
      model: "gpt-5-mini-2025-08-07",
      messages: [
        {
          role: "system",
          content:
            "VocÃª Ã© a Betgram IA â€” especialista em anÃ¡lises esportivas e apostas de valor. DÃª respostas objetivas e fundamentadas.",
        },
        { role: "user", content: prompt },
      ],
      max_completion_tokens: 2000,
    });

    const resposta =
      completion.choices?.[0]?.message?.content?.trim() ||
      "(sem texto retornado pelo modelo)";

    console.log("âœ… Resposta recebida:", resposta.slice(0, 150) + "...");

    return new Response(JSON.stringify({ resposta }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  } catch (err) {
    console.error("ðŸš¨ Erro /api/analise:", err?.response?.data || err);
    const msg =
      err?.response?.data?.error?.message ||
      err?.message ||
      "Falha ao gerar anÃ¡lise.";
    return new Response(JSON.stringify({ error: msg }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
