import "dotenv/config";
import OpenAI from "openai";

/**
 * API interna que processa requisiÃ§Ãµes da Betgram IA.
 * Roda no backend e tem acesso Ã s variÃ¡veis .env.local
 */
export async function POST(req) {
  try {
    const { prompt } = await req.json();

    // ðŸ”’ ValidaÃ§Ã£o de entrada
    if (!prompt || typeof prompt !== "string" || prompt.trim().length < 3) {
      return new Response(JSON.stringify({ error: "Prompt invÃ¡lido." }), {
        status: 400,
      });
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return new Response(
        JSON.stringify({
          error: "OPENAI_API_KEY ausente no servidor (.env.local).",
        }),
        { status: 500 }
      );
    }

    // âœ… Instancia o cliente OpenAI
    const openai = new OpenAI({ apiKey });

    // âš™ï¸ Chamada Ã  API
    const completion = await openai.chat.completions.create({
      model: "gpt-5-mini", // modelo rÃ¡pido e econÃ´mico
      messages: [{ role: "user", content: prompt }],
      temperature: 0.3,
      max_tokens: 3500, // ajuste para o limite que vocÃª definiu
    });

    // âœ… Garante que hÃ¡ resposta antes de enviar
    const resposta =
      completion.choices?.[0]?.message?.content?.trim() || "Sem resposta.";
    return new Response(JSON.stringify({ resposta }), { status: 200 });
  } catch (err) {
    console.error("ðŸš¨ Erro /api/analise:", err);
    return new Response(
      JSON.stringify({ error: "Falha ao gerar anÃ¡lise." }),
      { status: 500 }
    );
  }
}
